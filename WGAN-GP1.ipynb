{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c458e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable, grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bfc02b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Opt:\n",
    "    img_size = 64  # Image dimensions\n",
    "    latent_dim = 100  # Latent vector dimensions\n",
    "    n_epochs = 40  # Number of epochs\n",
    "    batch_size = 64  # Batch size\n",
    "    lr = 0.0002  # Learning rate\n",
    "    b1 = 0.5  # Beta1 for Adam optimizer\n",
    "    b2 = 0.999  # Beta2 for Adam optimizer\n",
    "    n_critic = 5  # Number of critic iterations\n",
    "    sample_interval = 100  # Interval for saving images\n",
    "opt = Opt()\n",
    "\n",
    "# Define image shape\n",
    "img_shape = (3, opt.img_size, opt.img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce38144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(opt.latent_dim, 128 * 8 * 8),\n",
    "            nn.BatchNorm1d(128 * 8 * 8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Unflatten(1, (128, 8, 8)),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(32, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e7121f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(img_shape[0], 32, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(32, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 1, 4, 1, 0, bias=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.model(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff83cb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_gp = 10\n",
    " \n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "\n",
    "# Configure data loader\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(opt.img_size),\n",
    "    transforms.CenterCrop(opt.img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "dataset = datasets.ImageFolder(root='D:\\\\Monotype_project\\\\cat1\\\\cat', transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=opt.batch_size, shuffle=True)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1f03c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    batch_size = real_samples.size(0)\n",
    "    alpha = Tensor(np.random.random((batch_size, 1, 1, 1)))  # Correct shape: (batch_size, 1, 1, 1)\n",
    "    \n",
    "    # Interpolate between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    \n",
    "    # Get discriminator output for interpolates\n",
    "    d_interpolates = D(interpolates)\n",
    "    \n",
    "    # Create labels for gradient penalty calculation\n",
    "    fake = Variable(Tensor(batch_size, 1).fill_(1.0), requires_grad=False)\n",
    "    \n",
    "    # Compute gradients with respect to interpolates\n",
    "    gradients = grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=torch.ones_like(d_interpolates),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True\n",
    "    )[0]\n",
    "    \n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    \n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc31f7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/40] [Batch 0/27] [D loss: 254.419418] [G loss: -0.212364]\n",
      "[Epoch 0/40] [Batch 5/27] [D loss: 43.381523] [G loss: -0.216682]\n",
      "[Epoch 0/40] [Batch 10/27] [D loss: 12.936790] [G loss: -0.228684]\n",
      "[Epoch 0/40] [Batch 15/27] [D loss: 3.656183] [G loss: -0.225624]\n",
      "[Epoch 0/40] [Batch 20/27] [D loss: 1.225814] [G loss: -0.223394]\n",
      "[Epoch 0/40] [Batch 25/27] [D loss: 0.751293] [G loss: -0.228175]\n",
      "[Epoch 1/40] [Batch 0/27] [D loss: 0.816999] [G loss: -0.252984]\n",
      "[Epoch 1/40] [Batch 5/27] [D loss: 0.225553] [G loss: -0.265290]\n",
      "[Epoch 1/40] [Batch 10/27] [D loss: 0.573571] [G loss: -0.265914]\n",
      "[Epoch 1/40] [Batch 15/27] [D loss: 0.266043] [G loss: -0.272925]\n",
      "[Epoch 1/40] [Batch 20/27] [D loss: 0.231930] [G loss: -0.269910]\n",
      "[Epoch 1/40] [Batch 25/27] [D loss: 0.328819] [G loss: -0.262043]\n",
      "[Epoch 2/40] [Batch 0/27] [D loss: 0.325584] [G loss: -0.281127]\n",
      "[Epoch 2/40] [Batch 5/27] [D loss: 0.294725] [G loss: -0.265568]\n",
      "[Epoch 2/40] [Batch 10/27] [D loss: 0.197853] [G loss: -0.243684]\n",
      "[Epoch 2/40] [Batch 15/27] [D loss: 0.169983] [G loss: -0.221014]\n",
      "[Epoch 2/40] [Batch 20/27] [D loss: 0.176470] [G loss: -0.188854]\n",
      "[Epoch 2/40] [Batch 25/27] [D loss: 0.110867] [G loss: -0.157932]\n",
      "[Epoch 3/40] [Batch 0/27] [D loss: 0.113974] [G loss: -0.167336]\n",
      "[Epoch 3/40] [Batch 5/27] [D loss: 0.160626] [G loss: -0.146725]\n",
      "[Epoch 3/40] [Batch 10/27] [D loss: 0.133712] [G loss: -0.114266]\n",
      "[Epoch 3/40] [Batch 15/27] [D loss: 0.045348] [G loss: -0.083892]\n",
      "[Epoch 3/40] [Batch 20/27] [D loss: 0.019948] [G loss: -0.073880]\n",
      "[Epoch 3/40] [Batch 25/27] [D loss: 0.001850] [G loss: -0.050646]\n",
      "[Epoch 4/40] [Batch 0/27] [D loss: 0.246535] [G loss: -0.080211]\n",
      "[Epoch 4/40] [Batch 5/27] [D loss: 0.050756] [G loss: -0.066308]\n",
      "[Epoch 4/40] [Batch 10/27] [D loss: -0.003971] [G loss: -0.048482]\n",
      "[Epoch 4/40] [Batch 15/27] [D loss: 0.011056] [G loss: -0.038064]\n",
      "[Epoch 4/40] [Batch 20/27] [D loss: -0.008514] [G loss: -0.014466]\n",
      "[Epoch 4/40] [Batch 25/27] [D loss: -0.019320] [G loss: 0.014904]\n",
      "[Epoch 5/40] [Batch 0/27] [D loss: -0.018323] [G loss: -0.012468]\n",
      "[Epoch 5/40] [Batch 5/27] [D loss: -0.072024] [G loss: 0.015058]\n",
      "[Epoch 5/40] [Batch 10/27] [D loss: -0.041321] [G loss: 0.054383]\n",
      "[Epoch 5/40] [Batch 15/27] [D loss: -0.154698] [G loss: 0.091906]\n",
      "[Epoch 5/40] [Batch 20/27] [D loss: -0.185659] [G loss: 0.134273]\n",
      "[Epoch 5/40] [Batch 25/27] [D loss: -0.077223] [G loss: 0.164305]\n",
      "[Epoch 6/40] [Batch 0/27] [D loss: -0.177613] [G loss: 0.125716]\n",
      "[Epoch 6/40] [Batch 5/27] [D loss: -0.162681] [G loss: 0.144907]\n",
      "[Epoch 6/40] [Batch 10/27] [D loss: -0.188559] [G loss: 0.178112]\n",
      "[Epoch 6/40] [Batch 15/27] [D loss: -0.221245] [G loss: 0.190006]\n",
      "[Epoch 6/40] [Batch 20/27] [D loss: -0.058825] [G loss: 0.207837]\n",
      "[Epoch 6/40] [Batch 25/27] [D loss: -0.261452] [G loss: 0.232806]\n",
      "[Epoch 7/40] [Batch 0/27] [D loss: -0.183704] [G loss: 0.176791]\n",
      "[Epoch 7/40] [Batch 5/27] [D loss: -0.236275] [G loss: 0.190639]\n",
      "[Epoch 7/40] [Batch 10/27] [D loss: -0.276129] [G loss: 0.206996]\n",
      "[Epoch 7/40] [Batch 15/27] [D loss: -0.074588] [G loss: 0.214826]\n",
      "[Epoch 7/40] [Batch 20/27] [D loss: -0.192063] [G loss: 0.248482]\n",
      "[Epoch 7/40] [Batch 25/27] [D loss: -0.307755] [G loss: 0.268378]\n",
      "[Epoch 8/40] [Batch 0/27] [D loss: -0.278610] [G loss: 0.217275]\n",
      "[Epoch 8/40] [Batch 5/27] [D loss: -0.349214] [G loss: 0.274190]\n",
      "[Epoch 8/40] [Batch 10/27] [D loss: -0.368094] [G loss: 0.342556]\n",
      "[Epoch 8/40] [Batch 15/27] [D loss: -0.464313] [G loss: 0.410337]\n",
      "[Epoch 8/40] [Batch 20/27] [D loss: -0.379509] [G loss: 0.430838]\n",
      "[Epoch 8/40] [Batch 25/27] [D loss: -0.463150] [G loss: 0.390429]\n",
      "[Epoch 9/40] [Batch 0/27] [D loss: -0.366610] [G loss: 0.293694]\n",
      "[Epoch 9/40] [Batch 5/27] [D loss: -0.319668] [G loss: 0.249387]\n",
      "[Epoch 9/40] [Batch 10/27] [D loss: -0.302925] [G loss: 0.219098]\n",
      "[Epoch 9/40] [Batch 15/27] [D loss: -0.125822] [G loss: 0.191396]\n",
      "[Epoch 9/40] [Batch 20/27] [D loss: -0.056520] [G loss: 0.201411]\n",
      "[Epoch 9/40] [Batch 25/27] [D loss: -0.215572] [G loss: 0.234998]\n",
      "[Epoch 10/40] [Batch 0/27] [D loss: -0.283766] [G loss: 0.197987]\n",
      "[Epoch 10/40] [Batch 5/27] [D loss: -0.300572] [G loss: 0.210705]\n",
      "[Epoch 10/40] [Batch 10/27] [D loss: -0.264751] [G loss: 0.243418]\n",
      "[Epoch 10/40] [Batch 15/27] [D loss: -0.314849] [G loss: 0.271155]\n",
      "[Epoch 10/40] [Batch 20/27] [D loss: -0.315861] [G loss: 0.274451]\n",
      "[Epoch 10/40] [Batch 25/27] [D loss: -0.303556] [G loss: 0.225880]\n",
      "[Epoch 11/40] [Batch 0/27] [D loss: -0.121033] [G loss: 0.122047]\n",
      "[Epoch 11/40] [Batch 5/27] [D loss: -0.067270] [G loss: 0.082503]\n",
      "[Epoch 11/40] [Batch 10/27] [D loss: -0.097786] [G loss: 0.074029]\n",
      "[Epoch 11/40] [Batch 15/27] [D loss: -0.095427] [G loss: 0.068960]\n",
      "[Epoch 11/40] [Batch 20/27] [D loss: -0.099639] [G loss: 0.074107]\n",
      "[Epoch 11/40] [Batch 25/27] [D loss: -0.169444] [G loss: 0.077943]\n",
      "[Epoch 12/40] [Batch 0/27] [D loss: -0.153430] [G loss: 0.057095]\n",
      "[Epoch 12/40] [Batch 5/27] [D loss: -0.156088] [G loss: 0.060902]\n",
      "[Epoch 12/40] [Batch 10/27] [D loss: -0.128180] [G loss: 0.078216]\n",
      "[Epoch 12/40] [Batch 15/27] [D loss: -0.007080] [G loss: 0.077523]\n",
      "[Epoch 12/40] [Batch 20/27] [D loss: -0.188424] [G loss: 0.081041]\n",
      "[Epoch 12/40] [Batch 25/27] [D loss: -0.062576] [G loss: 0.079860]\n",
      "[Epoch 13/40] [Batch 0/27] [D loss: -0.117586] [G loss: 0.070292]\n",
      "[Epoch 13/40] [Batch 5/27] [D loss: -0.146088] [G loss: 0.089675]\n",
      "[Epoch 13/40] [Batch 10/27] [D loss: -0.107703] [G loss: 0.069989]\n",
      "[Epoch 13/40] [Batch 15/27] [D loss: 0.501390] [G loss: 0.055825]\n",
      "[Epoch 13/40] [Batch 20/27] [D loss: -0.092853] [G loss: 0.038326]\n",
      "[Epoch 13/40] [Batch 25/27] [D loss: -0.087344] [G loss: 0.039625]\n",
      "[Epoch 14/40] [Batch 0/27] [D loss: -0.107683] [G loss: 0.022005]\n",
      "[Epoch 14/40] [Batch 5/27] [D loss: -0.087866] [G loss: 0.020286]\n",
      "[Epoch 14/40] [Batch 10/27] [D loss: -0.012788] [G loss: 0.007936]\n",
      "[Epoch 14/40] [Batch 15/27] [D loss: -0.071166] [G loss: 0.026771]\n",
      "[Epoch 14/40] [Batch 20/27] [D loss: 0.145266] [G loss: 0.009376]\n",
      "[Epoch 14/40] [Batch 25/27] [D loss: -0.023711] [G loss: 0.025004]\n",
      "[Epoch 15/40] [Batch 0/27] [D loss: -0.028399] [G loss: 0.013388]\n",
      "[Epoch 15/40] [Batch 5/27] [D loss: -0.050684] [G loss: 0.026147]\n",
      "[Epoch 15/40] [Batch 10/27] [D loss: 0.068896] [G loss: 0.045449]\n",
      "[Epoch 15/40] [Batch 15/27] [D loss: -0.082522] [G loss: 0.063547]\n",
      "[Epoch 15/40] [Batch 20/27] [D loss: -0.008045] [G loss: 0.063675]\n",
      "[Epoch 15/40] [Batch 25/27] [D loss: -0.084120] [G loss: 0.084950]\n",
      "[Epoch 16/40] [Batch 0/27] [D loss: 0.013327] [G loss: 0.063484]\n",
      "[Epoch 16/40] [Batch 5/27] [D loss: 0.028422] [G loss: 0.056797]\n",
      "[Epoch 16/40] [Batch 10/27] [D loss: -0.060499] [G loss: 0.062813]\n",
      "[Epoch 16/40] [Batch 15/27] [D loss: -0.082164] [G loss: 0.065762]\n",
      "[Epoch 16/40] [Batch 20/27] [D loss: -0.057030] [G loss: 0.056840]\n",
      "[Epoch 16/40] [Batch 25/27] [D loss: -0.047905] [G loss: 0.056984]\n",
      "[Epoch 17/40] [Batch 0/27] [D loss: -0.014014] [G loss: 0.032790]\n",
      "[Epoch 17/40] [Batch 5/27] [D loss: -0.049209] [G loss: 0.031689]\n",
      "[Epoch 17/40] [Batch 10/27] [D loss: 0.097372] [G loss: 0.019388]\n",
      "[Epoch 17/40] [Batch 15/27] [D loss: -0.003431] [G loss: 0.020463]\n",
      "[Epoch 17/40] [Batch 20/27] [D loss: -0.041257] [G loss: 0.021681]\n",
      "[Epoch 17/40] [Batch 25/27] [D loss: -0.012765] [G loss: 0.020266]\n",
      "[Epoch 18/40] [Batch 0/27] [D loss: -0.052096] [G loss: 0.018817]\n",
      "[Epoch 18/40] [Batch 5/27] [D loss: -0.040541] [G loss: 0.017546]\n",
      "[Epoch 18/40] [Batch 10/27] [D loss: -0.050772] [G loss: 0.025013]\n",
      "[Epoch 18/40] [Batch 15/27] [D loss: -0.037030] [G loss: 0.018945]\n",
      "[Epoch 18/40] [Batch 20/27] [D loss: -0.044435] [G loss: 0.007326]\n",
      "[Epoch 18/40] [Batch 25/27] [D loss: -0.042459] [G loss: 0.021977]\n",
      "[Epoch 19/40] [Batch 0/27] [D loss: -0.046750] [G loss: 0.010675]\n",
      "[Epoch 19/40] [Batch 5/27] [D loss: -0.063340] [G loss: 0.010046]\n",
      "[Epoch 19/40] [Batch 10/27] [D loss: -0.069811] [G loss: 0.012365]\n",
      "[Epoch 19/40] [Batch 15/27] [D loss: -0.102254] [G loss: 0.014679]\n",
      "[Epoch 19/40] [Batch 20/27] [D loss: -0.037863] [G loss: -0.003205]\n",
      "[Epoch 19/40] [Batch 25/27] [D loss: -0.053826] [G loss: 0.004288]\n",
      "[Epoch 20/40] [Batch 0/27] [D loss: -0.074671] [G loss: -0.003854]\n",
      "[Epoch 20/40] [Batch 5/27] [D loss: 0.221219] [G loss: -0.017121]\n",
      "[Epoch 20/40] [Batch 10/27] [D loss: -0.063744] [G loss: -0.023155]\n",
      "[Epoch 20/40] [Batch 15/27] [D loss: -0.054094] [G loss: -0.017010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20/40] [Batch 20/27] [D loss: -0.056618] [G loss: -0.029042]\n",
      "[Epoch 20/40] [Batch 25/27] [D loss: -0.038745] [G loss: -0.023832]\n",
      "[Epoch 21/40] [Batch 0/27] [D loss: -0.014799] [G loss: -0.039310]\n",
      "[Epoch 21/40] [Batch 5/27] [D loss: -0.051334] [G loss: -0.046424]\n",
      "[Epoch 21/40] [Batch 10/27] [D loss: -0.077389] [G loss: -0.040305]\n",
      "[Epoch 21/40] [Batch 15/27] [D loss: -0.042203] [G loss: -0.047645]\n",
      "[Epoch 21/40] [Batch 20/27] [D loss: -0.057056] [G loss: -0.051532]\n",
      "[Epoch 21/40] [Batch 25/27] [D loss: -0.054996] [G loss: -0.055289]\n",
      "[Epoch 22/40] [Batch 0/27] [D loss: -0.038390] [G loss: -0.064214]\n",
      "[Epoch 22/40] [Batch 5/27] [D loss: -0.063942] [G loss: -0.064011]\n",
      "[Epoch 22/40] [Batch 10/27] [D loss: -0.045897] [G loss: -0.069403]\n",
      "[Epoch 22/40] [Batch 15/27] [D loss: -0.067881] [G loss: -0.060416]\n",
      "[Epoch 22/40] [Batch 20/27] [D loss: -0.057252] [G loss: -0.066961]\n",
      "[Epoch 22/40] [Batch 25/27] [D loss: -0.042588] [G loss: -0.065121]\n",
      "[Epoch 23/40] [Batch 0/27] [D loss: -0.050974] [G loss: -0.081274]\n",
      "[Epoch 23/40] [Batch 5/27] [D loss: -0.077025] [G loss: -0.075447]\n",
      "[Epoch 23/40] [Batch 10/27] [D loss: -0.017216] [G loss: -0.074528]\n",
      "[Epoch 23/40] [Batch 15/27] [D loss: 0.015280] [G loss: -0.083803]\n",
      "[Epoch 23/40] [Batch 20/27] [D loss: -0.069445] [G loss: -0.090913]\n",
      "[Epoch 23/40] [Batch 25/27] [D loss: -0.013499] [G loss: -0.092855]\n",
      "[Epoch 24/40] [Batch 0/27] [D loss: -0.027046] [G loss: -0.100684]\n",
      "[Epoch 24/40] [Batch 5/27] [D loss: -0.021727] [G loss: -0.094089]\n",
      "[Epoch 24/40] [Batch 10/27] [D loss: -0.028947] [G loss: -0.106104]\n",
      "[Epoch 24/40] [Batch 15/27] [D loss: -0.058817] [G loss: -0.100080]\n",
      "[Epoch 24/40] [Batch 20/27] [D loss: -0.079453] [G loss: -0.101490]\n",
      "[Epoch 24/40] [Batch 25/27] [D loss: -0.041945] [G loss: -0.107814]\n",
      "[Epoch 25/40] [Batch 0/27] [D loss: -0.053269] [G loss: -0.118577]\n",
      "[Epoch 25/40] [Batch 5/27] [D loss: -0.062046] [G loss: -0.115649]\n",
      "[Epoch 25/40] [Batch 10/27] [D loss: -0.087785] [G loss: -0.104658]\n",
      "[Epoch 25/40] [Batch 15/27] [D loss: 0.004111] [G loss: -0.112761]\n",
      "[Epoch 25/40] [Batch 20/27] [D loss: -0.056805] [G loss: -0.119832]\n",
      "[Epoch 25/40] [Batch 25/27] [D loss: 0.015227] [G loss: -0.104575]\n",
      "[Epoch 26/40] [Batch 0/27] [D loss: -0.064777] [G loss: -0.126724]\n",
      "[Epoch 26/40] [Batch 5/27] [D loss: 0.121356] [G loss: -0.128003]\n",
      "[Epoch 26/40] [Batch 10/27] [D loss: -0.039771] [G loss: -0.120699]\n",
      "[Epoch 26/40] [Batch 15/27] [D loss: -0.076881] [G loss: -0.115762]\n",
      "[Epoch 26/40] [Batch 20/27] [D loss: -0.069343] [G loss: -0.118653]\n",
      "[Epoch 26/40] [Batch 25/27] [D loss: -0.072769] [G loss: -0.104161]\n",
      "[Epoch 27/40] [Batch 0/27] [D loss: 0.024980] [G loss: -0.109024]\n",
      "[Epoch 27/40] [Batch 5/27] [D loss: -0.076192] [G loss: -0.110050]\n",
      "[Epoch 27/40] [Batch 10/27] [D loss: -0.079300] [G loss: -0.096144]\n",
      "[Epoch 27/40] [Batch 15/27] [D loss: 0.024450] [G loss: -0.097265]\n",
      "[Epoch 27/40] [Batch 20/27] [D loss: -0.077205] [G loss: -0.089824]\n",
      "[Epoch 27/40] [Batch 25/27] [D loss: -0.093333] [G loss: -0.074591]\n",
      "[Epoch 28/40] [Batch 0/27] [D loss: 0.071279] [G loss: -0.089848]\n",
      "[Epoch 28/40] [Batch 5/27] [D loss: -0.069021] [G loss: -0.092403]\n",
      "[Epoch 28/40] [Batch 10/27] [D loss: -0.066219] [G loss: -0.097457]\n",
      "[Epoch 28/40] [Batch 15/27] [D loss: -0.092662] [G loss: -0.079739]\n",
      "[Epoch 28/40] [Batch 20/27] [D loss: -0.067232] [G loss: -0.095503]\n",
      "[Epoch 28/40] [Batch 25/27] [D loss: -0.080597] [G loss: -0.090711]\n",
      "[Epoch 29/40] [Batch 0/27] [D loss: -0.065021] [G loss: -0.105263]\n",
      "[Epoch 29/40] [Batch 5/27] [D loss: -0.059874] [G loss: -0.106785]\n",
      "[Epoch 29/40] [Batch 10/27] [D loss: -0.033711] [G loss: -0.101204]\n",
      "[Epoch 29/40] [Batch 15/27] [D loss: -0.039067] [G loss: -0.097315]\n",
      "[Epoch 29/40] [Batch 20/27] [D loss: -0.065206] [G loss: -0.093679]\n",
      "[Epoch 29/40] [Batch 25/27] [D loss: -0.062119] [G loss: -0.103431]\n",
      "[Epoch 30/40] [Batch 0/27] [D loss: -0.052657] [G loss: -0.113593]\n",
      "[Epoch 30/40] [Batch 5/27] [D loss: -0.064325] [G loss: -0.102181]\n",
      "[Epoch 30/40] [Batch 10/27] [D loss: -0.057844] [G loss: -0.112526]\n",
      "[Epoch 30/40] [Batch 15/27] [D loss: -0.033320] [G loss: -0.115726]\n",
      "[Epoch 30/40] [Batch 20/27] [D loss: -0.021487] [G loss: -0.119834]\n",
      "[Epoch 30/40] [Batch 25/27] [D loss: -0.052934] [G loss: -0.125033]\n",
      "[Epoch 31/40] [Batch 0/27] [D loss: -0.036376] [G loss: -0.130539]\n",
      "[Epoch 31/40] [Batch 5/27] [D loss: -0.042208] [G loss: -0.134312]\n",
      "[Epoch 31/40] [Batch 10/27] [D loss: 0.043116] [G loss: -0.126895]\n",
      "[Epoch 31/40] [Batch 15/27] [D loss: -0.052868] [G loss: -0.133938]\n",
      "[Epoch 31/40] [Batch 20/27] [D loss: -0.040076] [G loss: -0.138182]\n",
      "[Epoch 31/40] [Batch 25/27] [D loss: -0.010785] [G loss: -0.145430]\n",
      "[Epoch 32/40] [Batch 0/27] [D loss: -0.049285] [G loss: -0.148600]\n",
      "[Epoch 32/40] [Batch 5/27] [D loss: -0.029165] [G loss: -0.157429]\n",
      "[Epoch 32/40] [Batch 10/27] [D loss: -0.038679] [G loss: -0.158453]\n",
      "[Epoch 32/40] [Batch 15/27] [D loss: 0.006959] [G loss: -0.164763]\n",
      "[Epoch 32/40] [Batch 20/27] [D loss: -0.019148] [G loss: -0.164126]\n",
      "[Epoch 32/40] [Batch 25/27] [D loss: -0.035970] [G loss: -0.160232]\n",
      "[Epoch 33/40] [Batch 0/27] [D loss: -0.033189] [G loss: -0.173803]\n",
      "[Epoch 33/40] [Batch 5/27] [D loss: -0.027967] [G loss: -0.170326]\n",
      "[Epoch 33/40] [Batch 10/27] [D loss: -0.022513] [G loss: -0.170048]\n",
      "[Epoch 33/40] [Batch 15/27] [D loss: 0.246250] [G loss: -0.175832]\n",
      "[Epoch 33/40] [Batch 20/27] [D loss: -0.040881] [G loss: -0.179620]\n",
      "[Epoch 33/40] [Batch 25/27] [D loss: -0.043605] [G loss: -0.182306]\n",
      "[Epoch 34/40] [Batch 0/27] [D loss: -0.038956] [G loss: -0.186513]\n",
      "[Epoch 34/40] [Batch 5/27] [D loss: -0.022652] [G loss: -0.185387]\n",
      "[Epoch 34/40] [Batch 10/27] [D loss: -0.036990] [G loss: -0.183075]\n",
      "[Epoch 34/40] [Batch 15/27] [D loss: -0.030888] [G loss: -0.191629]\n",
      "[Epoch 34/40] [Batch 20/27] [D loss: -0.049119] [G loss: -0.188727]\n",
      "[Epoch 34/40] [Batch 25/27] [D loss: -0.009324] [G loss: -0.186223]\n",
      "[Epoch 35/40] [Batch 0/27] [D loss: -0.026136] [G loss: -0.192653]\n",
      "[Epoch 35/40] [Batch 5/27] [D loss: -0.031675] [G loss: -0.197516]\n",
      "[Epoch 35/40] [Batch 10/27] [D loss: -0.010770] [G loss: -0.198365]\n",
      "[Epoch 35/40] [Batch 15/27] [D loss: -0.028829] [G loss: -0.201372]\n",
      "[Epoch 35/40] [Batch 20/27] [D loss: -0.031091] [G loss: -0.203259]\n",
      "[Epoch 35/40] [Batch 25/27] [D loss: -0.015393] [G loss: -0.201465]\n",
      "[Epoch 36/40] [Batch 0/27] [D loss: -0.003229] [G loss: -0.209341]\n",
      "[Epoch 36/40] [Batch 5/27] [D loss: -0.004424] [G loss: -0.211120]\n",
      "[Epoch 36/40] [Batch 10/27] [D loss: -0.038568] [G loss: -0.210101]\n",
      "[Epoch 36/40] [Batch 15/27] [D loss: -0.019582] [G loss: -0.216114]\n",
      "[Epoch 36/40] [Batch 20/27] [D loss: 0.051499] [G loss: -0.213269]\n",
      "[Epoch 36/40] [Batch 25/27] [D loss: -0.015961] [G loss: -0.215294]\n",
      "[Epoch 37/40] [Batch 0/27] [D loss: -0.020262] [G loss: -0.221082]\n",
      "[Epoch 37/40] [Batch 5/27] [D loss: 0.133024] [G loss: -0.215229]\n",
      "[Epoch 37/40] [Batch 10/27] [D loss: -0.032338] [G loss: -0.208149]\n",
      "[Epoch 37/40] [Batch 15/27] [D loss: 0.019516] [G loss: -0.215419]\n",
      "[Epoch 37/40] [Batch 20/27] [D loss: -0.027129] [G loss: -0.212033]\n",
      "[Epoch 37/40] [Batch 25/27] [D loss: -0.025414] [G loss: -0.214494]\n",
      "[Epoch 38/40] [Batch 0/27] [D loss: -0.000820] [G loss: -0.216803]\n",
      "[Epoch 38/40] [Batch 5/27] [D loss: 0.001157] [G loss: -0.215042]\n",
      "[Epoch 38/40] [Batch 10/27] [D loss: -0.023158] [G loss: -0.214035]\n",
      "[Epoch 38/40] [Batch 15/27] [D loss: -0.018086] [G loss: -0.219618]\n",
      "[Epoch 38/40] [Batch 20/27] [D loss: -0.000453] [G loss: -0.214104]\n",
      "[Epoch 38/40] [Batch 25/27] [D loss: 0.002957] [G loss: -0.215294]\n",
      "[Epoch 39/40] [Batch 0/27] [D loss: 0.030683] [G loss: -0.220304]\n",
      "[Epoch 39/40] [Batch 5/27] [D loss: -0.001055] [G loss: -0.229810]\n",
      "[Epoch 39/40] [Batch 10/27] [D loss: -0.012921] [G loss: -0.218672]\n",
      "[Epoch 39/40] [Batch 15/27] [D loss: 0.033918] [G loss: -0.216753]\n",
      "[Epoch 39/40] [Batch 20/27] [D loss: -0.008223] [G loss: -0.208439]\n",
      "[Epoch 39/40] [Batch 25/27] [D loss: 0.002219] [G loss: -0.208021]\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store losses\n",
    "g_losses = []\n",
    "d_losses = []\n",
    "\n",
    "# Training\n",
    "batches_done = 0\n",
    "for epoch in range(opt.n_epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))\n",
    "        fake_imgs = generator(z)\n",
    "\n",
    "        real_validity = discriminator(real_imgs)\n",
    "        fake_validity = discriminator(fake_imgs.detach())\n",
    "        gradient_penalty = compute_gradient_penalty(discriminator, real_imgs.data, fake_imgs.data)\n",
    "        d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + lambda_gp * gradient_penalty\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Store Discriminator loss\n",
    "        d_losses.append(d_loss.item())\n",
    "\n",
    "        # Train the generator every n_critic steps\n",
    "        if i % opt.n_critic == 0:\n",
    "            optimizer_G.zero_grad()\n",
    "\n",
    "            fake_imgs = generator(z)\n",
    "            fake_validity = discriminator(fake_imgs)\n",
    "            g_loss = -torch.mean(fake_validity)\n",
    "\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            # Store Generator loss\n",
    "            g_losses.append(g_loss.item())\n",
    "\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "                % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
    "            )\n",
    "\n",
    "\n",
    "            batches_done += opt.n_critic\n",
    "        save_image(fake_imgs.data, f'images1/fake_images_epoch_{epoch+1}.png', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9fef51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save loss data\n",
    "np.save('g_losses.npy', g_losses)\n",
    "np.save('d_losses.npy', d_losses)\n",
    "\n",
    "# Plotting the loss curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(g_losses, label=\"G Loss\")\n",
    "plt.plot(d_losses, label=\"D Loss\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
